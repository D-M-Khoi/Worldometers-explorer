{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date\n",
    "today = datetime.date.today()\n",
    "# Amount of time for a page to fully load\n",
    "SLEEP_TIME_FOR_ELEMENTS_EXPLICIT = 30\n",
    "# Amount of time for all elements in a page to fully load\n",
    "SLEEP_TIME_FOR_ELEMENTS_IMPLICIT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome(\"chromedriver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scroll to the end of the page to load all elements\n",
    "* Execute script to scroll to the end of the page\n",
    "* Wait for elements to be loaded\n",
    "* Continue scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_page(sleep_time):\n",
    "    # Continuously scoll to the end of the page\n",
    "    # Configure sleep_time to wait for page loading\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\n",
    "            \"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(sleep_time)\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(soup):\n",
    "    attr = []\n",
    "    attr_raw = soup.find_all(\"th\",attrs={\"aria-controls\": re.compile(\"main_table_countries_today\")})\n",
    "    for i in range(len(attr_raw)):\n",
    "        attr.append(re.sub(\": .+\",\"\",attr_raw[i][\"aria-label\"]).replace('\\n','').replace(\"&nbsp;\",' '))\n",
    "    return attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "* Parse HTML to get instances one by one\n",
    "* ```day``` is used to decide which date should the data be crawled from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances(soup, day):\n",
    "    instances = []\n",
    "    # Select table to get correct data from 1 day\n",
    "    table = soup.find(\"table\", attrs={\"id\": f\"main_table_countries_{day}\"})\n",
    "    rows = table.find_all(\n",
    "        \"tr\", attrs={\"role\": \"row\", \"class\": [\"odd\", \"even\"]})\n",
    "    # Remove summary on the first row\n",
    "    rows.pop(0)\n",
    "    # For each instance parse to get data\n",
    "    for ins_raw in rows:\n",
    "        tmp = []\n",
    "        ins_r = ins_raw.find_all('td')\n",
    "        if len(ins_r) == 0:\n",
    "            continue\n",
    "        ins_r.pop(0)\n",
    "        if ins_r[0].string == None:\n",
    "            continue\n",
    "        tmp.append(ins_r[0].string.strip())\n",
    "        for i in range(1,len(ins_r) - 2):\n",
    "            if ins_r[i].string == None or len(ins_r[i].string.strip()) == 0:\n",
    "                tmp.append('N/A')\n",
    "            else:\n",
    "                tmp.append(ins_r[i].string.strip().replace(',',''))\n",
    "        # Get poplulation\n",
    "        if ins_r[-2].a != None:\n",
    "            tmp.append(ins_r[-2].a.string.strip().replace(',',''))\n",
    "        else:\n",
    "            tmp.append(ins_r[-2].string.strip().replace(',',''))\n",
    "        # Get continent\n",
    "        if ins_r[-1].string == None or len(ins_r[-1].string.strip()) == 0:\n",
    "            tmp.append('N/A')\n",
    "        else:\n",
    "            tmp.append(ins_r[-1].string.strip())\n",
    "        instances.append(tmp)\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename,attrs, instances):\n",
    "    with open(f\"data/{filename}.tsv\",\"w\") as f:\n",
    "        f.write('\\t'.join(attrs) + '\\n')\n",
    "        for i in instances:\n",
    "            f.write('\\t'.join(i) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling\n",
    "* Get data from most 3 recent days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 recent days\n",
    "day = [\n",
    "    \"today\", \n",
    "    \"yesterday\", \n",
    "    \"yesterday2\"\n",
    "    ]\n",
    "\n",
    "driver.get(\"https://www.worldometers.info/coronavirus/\")\n",
    "\n",
    "# Scrolling and get page source\n",
    "scroll_page(SLEEP_TIME_FOR_ELEMENTS_IMPLICIT)\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "# Crawling\n",
    "for i in range(len(day)):\n",
    "    driver.find_element_by_id(f'nav-{day[i]}-tab')\n",
    "    attrs = get_attributes(soup)\n",
    "    instances = get_instances(soup,day[i])\n",
    "    date = today - datetime.timedelta(days=i)\n",
    "    save_file(f\"worldometers-{date.strftime('%Y-%m-%d')}\",attrs,instances)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09d67bcd7ff13b9df5301fa22c4b79d210e46a32433d34b4a205d9ff5f62d182"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('min_ds-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
